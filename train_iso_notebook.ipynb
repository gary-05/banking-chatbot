{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08b1e669-c571-45e0-a6b6-93ab9b2a865c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# install if needed (uncomment to run)\n",
    "# !pip install scikit-learn pandas numpy sqlalchemy psycopg2-binary python-dotenv matplotlib\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sqlalchemy import create_engine\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2fe3cabe-8498-4994-b0b7-26ea031ed9d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting .env\n"
     ]
    }
   ],
   "source": [
    "%%writefile .env\n",
    "DELHI_DB=postgresql://postgres:DelhiBranch.01@db.lojhymwazlofficptjcy.supabase.co:5432/postgres\n",
    "MUMBAI_DB=postgresql://postgres:MumbaiBranch.01@db.bvnkorfmorhvpprwbdwv.supabase.co:5432/postgres\n",
    "MODEL_PATH=bank_project/models/iso_model.pkl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae79a214-6d00-461b-9178-b40671b737ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DELHI_DB: True\n",
      "MUMBAI_DB: True\n",
      "MODEL_PATH: bank_project/models/iso_model.pkl\n"
     ]
    }
   ],
   "source": [
    "# Configure these environment variables in your .env or replace strings below.\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "print(\"DELHI_DB:\", bool(os.getenv(\"DELHI_DB\")))\n",
    "print(\"MUMBAI_DB:\", bool(os.getenv(\"MUMBAI_DB\")))\n",
    "print(\"MODEL_PATH:\", os.getenv(\"MODEL_PATH\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "30f6a65a-5ff7-46b2-9d46-3d3528e8b77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURE_COLS = ['amount', 'hour', 'txn_freq_10min', 'daily_sum', 'balance', 'txn_type_encoded', 'branch_id']\n",
    "\n",
    "def load_features_from_db(conn_url, branch_id):\n",
    "    engine = create_engine(conn_url)\n",
    "    query = \"\"\"\n",
    "    WITH t AS (\n",
    "      SELECT tx.txn_id, tx.customer_id, tx.txn_type, tx.amount, tx.txn_time, a.balance\n",
    "      FROM transactions tx\n",
    "      LEFT JOIN account a ON a.customer_id = tx.customer_id\n",
    "    )\n",
    "    SELECT\n",
    "      txn_id,\n",
    "      customer_id,\n",
    "      EXTRACT(HOUR FROM txn_time) AS hour,\n",
    "      COALESCE(amount,0) AS amount,\n",
    "      (SELECT COUNT(*) FROM transactions tx2\n",
    "       WHERE tx2.customer_id = t.customer_id\n",
    "         AND tx2.txn_time BETWEEN t.txn_time - INTERVAL '10 minutes' AND t.txn_time\n",
    "      )::int AS txn_freq_10min,\n",
    "      (SELECT COALESCE(SUM(amount),0) FROM transactions tx3\n",
    "       WHERE tx3.customer_id = t.customer_id\n",
    "         AND DATE(tx3.txn_time) = DATE(t.txn_time)\n",
    "      ) AS daily_sum,\n",
    "      COALESCE(balance,0) as balance,\n",
    "      CASE WHEN txn_type ILIKE 'withdraw%' THEN 1 ELSE 0 END AS txn_type_encoded\n",
    "    FROM t;\n",
    "    \"\"\"\n",
    "    df = pd.read_sql(query, engine)\n",
    "    df['branch_id'] = branch_id\n",
    "    engine.dispose()\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "39b2db39-e8cb-4367-97d2-7c929892dee8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DELHI_DB: postgresql://postgres:DelhiBranch.01@db.lojhymwazlofficptjcy.supabase.co:5432/postgres\n",
      "MUMBAI_DB: postgresql://postgres:MumbaiBranch.01@db.bvnkorfmorhvpprwbdwv.supabase.co:5432/postgres\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "env_path = r\"C:\\Users\\VICTUS\\BANKING SYSTEM\\bank_project\\.env\"\n",
    "load_dotenv(env_path, override=True)\n",
    "\n",
    "print(\"DELHI_DB:\", os.getenv(\"DELHI_DB\"))\n",
    "print(\"MUMBAI_DB:\", os.getenv(\"MUMBAI_DB\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e2d527-55e1-4e56-a3de-89ce7bc0ae1b",
   "metadata": {},
   "source": [
    "### Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "83db9cea-d5eb-4795-bae9-837b06a672bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Delhi...\n",
      "Delhi rows: 19\n",
      "Loading Mumbai...\n",
      "Mumbai rows: 5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>txn_id</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>amount</th>\n",
       "      <th>txn_timestamp</th>\n",
       "      <th>balance</th>\n",
       "      <th>txn_type_num</th>\n",
       "      <th>branch_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>75000.0</td>\n",
       "      <td>1.760090e+09</td>\n",
       "      <td>75000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>15000.0</td>\n",
       "      <td>1.760090e+09</td>\n",
       "      <td>62000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>1.760090e+09</td>\n",
       "      <td>200000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1.762506e+09</td>\n",
       "      <td>153000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1.762506e+09</td>\n",
       "      <td>153000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   txn_id  customer_id    amount  txn_timestamp   balance  txn_type_num  \\\n",
       "0       3            3   75000.0   1.760090e+09   75000.0             0   \n",
       "1       4            4   15000.0   1.760090e+09   62000.0             0   \n",
       "2       5            5  100000.0   1.760090e+09  200000.0             0   \n",
       "3      17            2    1000.0   1.762506e+09  153000.0             0   \n",
       "4      15            2    1000.0   1.762506e+09  153000.0             0   \n",
       "\n",
       "   branch_id  \n",
       "0          0  \n",
       "1          0  \n",
       "2          0  \n",
       "3          0  \n",
       "4          0  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "def load_features_from_db(conn_url, branch_id):\n",
    "    engine = create_engine(conn_url)\n",
    "\n",
    "    query = \"\"\"\n",
    "    WITH t AS (\n",
    "      SELECT \n",
    "        tx.txn_id,\n",
    "        tx.customer_id,\n",
    "        tx.txn_type,\n",
    "        tx.amount,\n",
    "        tx.txn_time,\n",
    "        a.balance\n",
    "      FROM transactions tx\n",
    "      LEFT JOIN account a ON tx.customer_id = a.customer_id\n",
    "    )\n",
    "    SELECT\n",
    "      txn_id,\n",
    "      customer_id,\n",
    "      amount,\n",
    "      EXTRACT(EPOCH FROM txn_time) AS txn_timestamp,\n",
    "      balance,\n",
    "      CASE \n",
    "        WHEN txn_type = 'deposit' THEN 1\n",
    "        WHEN txn_type = 'withdraw' THEN -1\n",
    "        ELSE 0\n",
    "      END AS txn_type_num\n",
    "    FROM t;\n",
    "    \"\"\"\n",
    "\n",
    "    df = pd.read_sql(query, engine)\n",
    "    df[\"branch_id\"] = branch_id\n",
    "    engine.dispose()\n",
    "    return df\n",
    "\n",
    "\n",
    "# ---- Load BOTH databases ----\n",
    "print(\"Loading Delhi...\")\n",
    "df_delhi = load_features_from_db(os.getenv(\"DELHI_DB\"), branch_id=0)\n",
    "print(\"Delhi rows:\", len(df_delhi))\n",
    "\n",
    "print(\"Loading Mumbai...\")\n",
    "df_mumbai = load_features_from_db(os.getenv(\"MUMBAI_DB\"), branch_id=1)\n",
    "print(\"Mumbai rows:\", len(df_mumbai))\n",
    "\n",
    "# Merge\n",
    "df = pd.concat([df_delhi, df_mumbai], ignore_index=True)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70890628-a936-4542-ab6c-f8fee9228889",
   "metadata": {},
   "source": [
    "### Preprocess Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a1e7cc69-55b8-45dc-94e7-4f07684ef25e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (24, 4)\n",
      "Sample: [[ 0.819231   -0.26838452 -0.82875211  0.        ]\n",
      " [-0.28122855 -0.50228388 -0.82875211  0.        ]\n",
      " [ 1.27775582  1.98064776 -0.82875211  0.        ]\n",
      " [-0.53800245  1.13501162  1.29816245  0.        ]\n",
      " [-0.53800245  1.13501162  1.29815066  0.        ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Select only numeric features for model training\n",
    "feature_cols = [\"amount\",  \"balance\",\"txn_timestamp\", \"txn_type_num\"]\n",
    "\n",
    "df_train = df[feature_cols].copy()\n",
    "\n",
    "# Handle missing values (if any)\n",
    "df_train = df_train.fillna(0)\n",
    "\n",
    "# Scale the data\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(df_train)\n",
    "\n",
    "print(\"Shape:\", X_scaled.shape)\n",
    "print(\"Sample:\", X_scaled[:5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3671f09-4eb4-442f-bf61-9a2b1664aab0",
   "metadata": {},
   "source": [
    "### Train the Isolation Forest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c9a7afa6-72ad-47d9-a862-f49116086d47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained successfully!\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "import joblib\n",
    "\n",
    "# Train the model\n",
    "iso = IsolationForest(\n",
    "    n_estimators=200,\n",
    "    contamination=0.1,   # ~10% anomalies (adjustable)\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "iso.fit(X_scaled)\n",
    "\n",
    "print(\"Model trained successfully!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e41d910-0c4f-4dc8-98a2-f26a6d44611d",
   "metadata": {},
   "source": [
    "### Save the model + scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b209571b-79d2-4036-b433-b47648447b05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model and scaler to models folder\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "# Example training data\n",
    "df_train = pd.DataFrame({\n",
    "    'amount': [1000, 50000, 300, 20000, 4000],\n",
    "    'balance': [5000, 100000, 1500, 4000, 60000],\n",
    "    'txn_timestamp': [1699999999, 1700009999, 1700019999, 1700029999, 1700039999],\n",
    "    'txn_type_num': [0, 1, 0, 1, 0],\n",
    "})\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(df_train)\n",
    "\n",
    "# Train Isolation Forest\n",
    "iso_model = IsolationForest(contamination=0.1, random_state=42)\n",
    "iso_model.fit(X_scaled)\n",
    "\n",
    "# Save both\n",
    "os.makedirs(\"bank_project/models\", exist_ok=True)\n",
    "joblib.dump(iso_model, \"bank_project/models/iso_model.pkl\")\n",
    "joblib.dump(scaler, \"bank_project/models/scaler.pkl\")\n",
    "\n",
    "print(\"Saved model and scaler to models folder\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "01d1343f-ee1b-4ee5-8856-83cf3b482778",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: C:\\Users\\VICTUS\\BANKING SYSTEM\\bank_project\n",
      "Files in bank_project/models: ['iso_model.pkl', 'scaler.pkl']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "print(\"Current working directory:\", os.getcwd())\n",
    "print(\"Files in bank_project/models:\", os.listdir(\"bank_project/models\") if os.path.exists(\"bank_project/models\") else \"Folder does not exist\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6e0cbbdd-c808-439e-a39e-21fb847384e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to: bank_project/models/iso_model.pkl\n",
      "Saved scaler to: bank_project/models/scaler.pkl\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6411db63-5e9a-4f9e-b238-dc6038675e9e",
   "metadata": {},
   "source": [
    "### Detect anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e6917013-08be-4ccd-9a16-414a95391773",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   txn_id  customer_id  amount  balance  txn_type  fraud_flag\n",
      "0       1          101    1000     5000   deposit           0\n",
      "1       2          102   70000   100000  withdraw           1\n",
      "2       3          103     300     1500   deposit           0\n",
      "3       4          104   25000     4000  withdraw           0\n",
      "4       5          105    4000    60000   deposit           0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "\n",
    "# Paths\n",
    "MODEL_PATH = \"bank_project/models/iso_model.pkl\"\n",
    "SCALER_PATH = \"bank_project/models/scaler.pkl\"\n",
    "\n",
    "# Load model and scaler\n",
    "iso_model = joblib.load(MODEL_PATH)\n",
    "scaler = joblib.load(SCALER_PATH)\n",
    "\n",
    "# Example test dataframe\n",
    "df_test = pd.DataFrame({\n",
    "    'txn_id': [1, 2, 3, 4, 5],\n",
    "    'customer_id': [101, 102, 103, 104, 105],\n",
    "    'txn_type': ['deposit', 'withdraw', 'deposit', 'withdraw', 'deposit'],\n",
    "    'txn_time': pd.to_datetime([\n",
    "        '2025-11-16 09:00', \n",
    "        '2025-11-16 23:30', \n",
    "        '2025-11-16 14:00', \n",
    "        '2025-11-16 07:00', \n",
    "        '2025-11-16 16:00'\n",
    "    ]),\n",
    "    'amount': [1000, 70000, 300, 25000, 4000],\n",
    "    'balance': [5000, 100000, 1500, 4000, 60000]\n",
    "})\n",
    "\n",
    "# Prepare ML features\n",
    "df_test['txn_type_num'] = df_test['txn_type'].map({'deposit': 0, 'withdraw': 1}).fillna(0)\n",
    "df_test['txn_timestamp'] = df_test['txn_time'].astype('int64') // 10**9\n",
    "\n",
    "# Select features in SAME order as training\n",
    "feature_cols = [\"amount\", \"balance\", \"txn_timestamp\", \"txn_type_num\"]\n",
    "X_test_scaled = scaler.transform(df_test[feature_cols].fillna(0))\n",
    "\n",
    "# Predict anomalies\n",
    "df_test['fraud_flag'] = iso_model.predict(X_test_scaled)  # -1 = anomaly, 1 = normal\n",
    "df_test['fraud_flag'] = df_test['fraud_flag'].map({1: 0, -1: 1})  # 1 = fraud\n",
    "\n",
    "# Show results\n",
    "print(df_test[['txn_id', 'customer_id', 'amount', 'balance', 'txn_type', 'fraud_flag']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27865f34-de77-478d-8245-890ce2225e32",
   "metadata": {},
   "source": [
    "### hybrid function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "bb9b3ab4-1c4f-42fc-9de6-bfba23a5678d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def detect_fraud(df, model, scaler):\n",
    "    \"\"\"\n",
    "    Hybrid fraud detection: rule-based + ML-based\n",
    "    df: transaction dataframe with columns ['txn_id', 'customer_id', 'amount', 'txn_type', 'txn_time', 'balance']\n",
    "    model: trained IsolationForest model\n",
    "    scaler: trained StandardScaler\n",
    "    Returns: fraud_alerts dataframe\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # ---------------------\n",
    "    # 1️⃣ Rule-Based Checks\n",
    "    # ---------------------\n",
    "    df['rule_flag'] = 0\n",
    "    \n",
    "    # Ensure amount and balance columns exist\n",
    "    df['amount'] = pd.to_numeric(df.get('amount', 0), errors='coerce').fillna(0)\n",
    "    df['balance'] = pd.to_numeric(df.get('balance', 0), errors='coerce').fillna(0)\n",
    "    \n",
    "    # Rule 1: Large transaction (>50k)\n",
    "    df.loc[df['amount'] > 50000, 'rule_flag'] = 1\n",
    "    \n",
    "    # Rule 2: Transactions outside 8AM–8PM\n",
    "    if 'txn_time' in df.columns:\n",
    "        df['txn_time'] = pd.to_datetime(df['txn_time'], errors='coerce')\n",
    "        df['txn_hour'] = df['txn_time'].dt.hour.fillna(0)\n",
    "        df.loc[(df['txn_hour'] < 8) | (df['txn_hour'] > 20), 'rule_flag'] = 1\n",
    "    else:\n",
    "        df['txn_hour'] = 0\n",
    "    \n",
    "    # Rule 3: Withdrawals higher than current balance\n",
    "    df['txn_type'] = df.get('txn_type', 'deposit')\n",
    "    df.loc[(df['txn_type'] == 'withdraw') & (df['amount'] > df['balance']), 'rule_flag'] = 1\n",
    "    \n",
    "    # ---------------------\n",
    "    # 2️⃣ Prepare ML Features\n",
    "    # ---------------------\n",
    "    df['txn_type_num'] = df['txn_type'].map({'deposit': 0, 'withdraw': 1}).fillna(0)\n",
    "    df['txn_timestamp'] = df['txn_time'].astype('int64') // 10**9 if 'txn_time' in df.columns else 0\n",
    "    \n",
    "    # Correct feature order: amount, txn_type_num, txn_timestamp, balance\n",
    "    feature_cols = ['amount', 'balance', 'txn_timestamp', 'txn_type_num']\n",
    "    \n",
    "    X_scaled = scaler.transform(df[feature_cols].fillna(0))\n",
    "    \n",
    "    # ---------------------\n",
    "    # 3️⃣ ML-Based Detection\n",
    "    # ---------------------\n",
    "    df['ml_flag'] = model.predict(X_scaled)\n",
    "    df['ml_flag'] = df['ml_flag'].map({1: 0, -1: 1})  # 1 = fraud, 0 = normal\n",
    "    \n",
    "    # ---------------------\n",
    "    # 4️⃣ Combine Flags\n",
    "    # ---------------------\n",
    "    df['fraud_flag'] = df[['rule_flag', 'ml_flag']].max(axis=1)\n",
    "    \n",
    "    # ---------------------\n",
    "    # 5️⃣ Prepare Alerts\n",
    "    # ---------------------\n",
    "    fraud_alerts = df[df['fraud_flag'] == 1][['txn_id', 'customer_id']].copy()\n",
    "    fraud_alerts['alert_type'] = df.loc[fraud_alerts.index, 'ml_flag'].map({1: 'ml', 0: 'rule'})\n",
    "    fraud_alerts['score'] = df.loc[fraud_alerts.index, 'ml_flag']  # ML score for info\n",
    "    fraud_alerts['message'] = \"Potential fraud detected.\"\n",
    "    fraud_alerts['detected_at'] = pd.Timestamp.now()\n",
    "    \n",
    "    return fraud_alerts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "66a8ecd8-f888-40dd-9a38-52ae253e66ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   txn_id  customer_id alert_type  score                    message  \\\n",
      "1       2          102         ml      1  Potential fraud detected.   \n",
      "3       4          104       rule      0  Potential fraud detected.   \n",
      "\n",
      "                 detected_at  \n",
      "1 2025-11-16 18:43:20.463235  \n",
      "3 2025-11-16 18:43:20.463235  \n"
     ]
    }
   ],
   "source": [
    "fraud_alerts = detect_fraud(df_test, iso_model, scaler)\n",
    "print(fraud_alerts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "515d34a3-0952-452b-87b7-019c258690bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e3aae8-b8f1-4d72-8fdb-97c196516640",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0499b5a-c832-4288-9777-af50fff52bfc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb3b337-433c-4090-a8f7-c7bdbf01b3da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7920c307-a273-4180-ad01-ec57a847cf0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "txn_id             int64\n",
      "customer_id        int64\n",
      "amount           float64\n",
      "txn_timestamp    float64\n",
      "balance          float64\n",
      "txn_type_num       int64\n",
      "branch_id          int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df_delhi.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5468d690-5e0a-46ae-a2e8-c1aba88bec0f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
